# Отчет 

## по лабораторной работе №1 по дисциплине "Методы оптимизации"

Автор: Ахметов Марсель M3237

**Цель работы:**

- Реализовать предложенные методы
- Исследовать их

**Задачи:**

1. Реализовать градиентный спуск с постоянным шагом. Исследовать сходимость при различных значениях шага.
2. Подобрать функцию(например, экспоненциальную или ступенчатую) изменения шага, чтобы улучшить сходимость.
3. Реализовать методы одномерного спуска и градиентный спуск на его основе. Сравнить эффективность с точки зрения количества вычислений минимизируемой функции и её градиентов
4. Сделать одномерный поиск с учетом условий Вольфе и исследовать эффективность
5. Проанализировать траекторию градиентного спуска для нескольких квадратичных функциях, нарисовать их графики с линиями уровня и траекториями
6. Исследовать зависимость числа итераций, необходимоое для сходимости от следующих параметров: 
    1. Числа обусловленности k
    2. Размерности пространства n 


**Решение:**

1. Иии
    1. Реализовать градиентный спуск с постоянным шагом

                def optimize(self, func: BiFunction, stp=True) -> float:
                    func.reset_applying()
                    stop = False
                    start_point = copy(self.start)
                    next_point = copy(self.start)
                    lr = self.lr
                    while not stop:
                        print(start_point)
                        grad = func.count_gradient(start_point)
                        ln = mod(grad)
                        grad = grad / ln
                        <!-- lr *= 0.5 -->
                        <!-- if stp: -->
                            <!-- lr = get_new_alpha(func, start_point, grad) -->
                        next_point = start_point + grad * (-lr)
                        if ln < self.epsilon:
                            stop = True
                        start_point = next_point
                    return start_point

    2. Исследовать сходимость при различных значениях шага.